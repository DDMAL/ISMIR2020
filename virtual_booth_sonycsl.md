---
layout: page
title: Sony / SonyCSL
# hero_background: sponsors/Spotify.png
background_position: 0% 35% 
permalink: /sonycsl/
---

<head>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<style>
.fa {
  padding: 5px;
  font-size: 30px;
  width: 40px;
  text-align: center;
  text-decoration: none;
  margin: 5px 2px;
  border-radius: 30%;

}
.fa:hover {
    opacity: 0.7;
    color:white;
    text-decoration:none;
}
.fa-facebook {
  background: #3B5998;
  color: white;
}
.fa-twitter {
  background: #55ACEE;
  color: white;
}
.fa-linkedin {
  background: #007bb5;
  color: white;
}
.fa-instagram {
  background: #DD2A7B;
  color: white;
}
</style>
</head>


# Sony R&D - AI x Audio: From Research to Production

[<img src="{{ site.baseurl }}/assets/img/virtual-booth-sonycsl/sony_logo_blue_RGB.png" alt="sony banner" height="90px"/>](https://www.sony.net/)

Over its 70-year history, Sony has always sought to provide consumers with extraordinary, excellent-quality audio products right from the era of tape recorders and transistor radios.

We are also focused on using our speech processing, image processing, communication, mechatronics & motion control, semiconductor, sensing, and AI technologies to research and develop products, services and entertainment that enable customers to feel Sony's exciting "KANDO" power of emotional connection.

We have scheduled to hold sponsor events at ISMIR 2020 to introduce these technologies.

### Industry Poster
  1. 8A Thursday Oct 15th @ 17:35-18:55 UTC
  2. 8B Friday Oct 16th @ 6:05-7:25 UTC  

### Meetup with Industry Session
  1. Session A: Wednesday Oct 14th @ 14:30 UTC
  2. Session B: Thursday Oct 15th @ 2:30 UTC  

## 1. Researches

### Recent Works
* *D3Net: Densely connected multidilated DenseNet for music source separation*, from N. Takahashi and Y. Mitsufuji
    * [Paper](https://arxiv.org/abs/2010.01733)

* *All for One and One for All: Improving Music Separation by Bridging Networks*, from R. Sawata, S. Uhlich, S. Takahashi, and Y. Mitsufuji
    * [Paper]({{ site.baseurl }}/assets/img/virtual-booth-sonycsl/cUMX_paper.pdf)
 
* *Adversarial Attacks on Audio Source Separation*, from N. Takahashi, S. Inoue, and Y. Mitsufuji
    * [Paper](https://arxiv.org/abs/2010.03164)

More publications can be found [here](https://www.sony.net/SonyInfo/technology/works/).

## 2. Audio Products & Services Utilizing AI Technologies

### Karaoke Application

[<img src="{{ site.baseurl }}/assets/img/virtual-booth-sonycsl/in-app-karaoke-banner.jpg" width="360px" style="float: left;width: 360px; margin-right: 20px;">]({{ site.baseurl }}/assets/img/virtual-booth-sonycsl/Sony_demo_movie.mp4)

Sony's real-time version of music separation has been successfully deployed on mobile devices as an in-app Karaoke module. The demo video can be found in the link below. Please note that the volume of vocal can be controlled freely and the residual can be used to guide the pitch of a Karaoke user. This technology is being licensed to several digital service providers, e.g., Line Music Japan/Taiwan.

##### * Special thanks to Line Music Japan for the creation of this demonstration video.

#### Link
 * [Demo video]({{ site.baseurl }}/assets/img/virtual-booth-sonycsl/Sony_demo_movie.mp4)


### 360 Reality Audio

[<img src="{{ site.baseurl }}/assets/img/virtual-booth-sonycsl/sap-logo-360.jpg" width="360px" style="float: left;width: 360px; margin-right: 20px;">](https://www.sony.net/360RA/)

360 Reality Audio is a new music experience that uses Sony's object-based spatial audio technology.
Individual sounds such as vocals, chorus, piano, guitar, bass and even sounds of the live audience can be placed in a 360 spherical sound field, giving artists and creators a new way to express their creativity. Listeners can be immersed in a field of sound exactly as intended by artists and creators.

<br/>
![360 Reality Audio 1](https://www.sony.net/SonyInfo/sony_ai/icassp2020/assets/img/sap-figure-01-pc.jpg)
<br/>
<br/>

Optimization by personal ear data uses Sony's original estimation algorithm utilizing machine learning.
We analyze that listener's hearing characteristics by estimating the 3D shape of the ear based a photo of their ear through "Sony | Headphones Connect" app.

<br>
![360 Reality Audio 2](https://www.sony.net/SonyInfo/sony_ai/icassp2020/assets/img/sap-figure-02-pc.jpg)
<br>
<br>

#### Links
 * [360 Reality Audio official website](https://www.sony.net/360RA/)
 * [Explore artist stories about 360 Reality Audio on music storytelling platform Music.com](http://www.music.com/360RA/)

### Noise Cancelling Headphones

[<img src="{{ site.baseurl }}/assets/img/virtual-booth-sonycsl/sap-img-nc.jpg" width="360px" style="float: left;width: 360px; margin-right: 20px; margin-bottom: 20px;">](https://www.sony.com/electronics/truly-wireless/wf-1000xm3)

Adaptive Sound Control automatically adjusts to whatever you do.
The Sony | Headphones Connect app offers Adaptive Sound Control, a smart function that automatically detects what you're up to - such as traveling, walking, or waiting - then adjusts ambient sound settings to suit the situation. You can also customize the settings to your preferences.

##### *As of June 1, 2020. Ambient noise-reduction according to research by Sony Corporation, measured using JEITA-compliant guidelines in Truly Wireless style noise-canceling headphones market.

<br>
![Noise Cancelling Headphones](https://www.sony.net/SonyInfo/sony_ai/icassp2020/assets/img/sap-figure-03-pc.jpg)

#### Links
 * [Product Site of WF-1000XM3](https://www.sony.com/electronics/truly-wireless/wf-1000xm3)
 * [Special Movie](https://youtu.be/Vu36eoC50i0)
  

## 3. Recruiting Information
If you are interested in working with us, please click [here](https://www.sony.net/SonyInfo/Careers/jobinfo/ISMIR/) for more open positions of job and internship!

# Sony CSL - AI-Powered Music Production

![cslbanner]({{ site.baseurl }}/assets/img/virtual-booth-sonycsl/band.png)

## 1. Sony CSL Music Team

Created in 1996, the music team at Sony CSL works on innovative music production technologies. Researchers in the team focus on two domains : digital signal processing and music generation with deep learning.
The team has a rich history of publication at ISMIR. Last year, we have (co-authored) 4 papers:

* *Controlling Symbolic Music Generation based on Concept Learning from Domain Knowledge*, from **T. Akama** (CSL Tokyo)
    * [Talk](https://collegerama.tudelft.nl/Mediasite/Showcase/ismir2019/Presentation/dc7470995df8474db0df7bdfe7323d241d) & [paper](http://archives.ismir.net/ismir2019/paper/000100.pdf)

* *Auto-adaptive Resonance Equalization using Dilated Residual Networks*, from **M. Grachten** and **E. Deruty**
    * [Talk](https://collegerama.tudelft.nl/Mediasite/Showcase/ismir2019/Presentation/ff06d3c5da9b4df4b1aa203b1501f27b1d) & [paper](https://arxiv.org/abs/1807.08636)


* *Learning to Traverse Latent Spaces for Musical Score Inpainting*, from A. Pati, A. Lerch and **G. Hadjeres**
    * [Talk](https://collegerama.tudelft.nl/Mediasite/Showcase/ismir2019/Presentation/f287880ce8c2435fb16849401f895ab61d) & [paper](https://arxiv.org/abs/1907.01164)


* *Learning Complex Basis Functions for Invariant Representations of Audio*, from **S. Lattner**, M. Dorfler and A. Arzt, that won a **Best Paper Award**!
    * [Talk](https://collegerama.tudelft.nl/Mediasite/Showcase/ismir2019/Presentation/d4e108a29b29466f90f4708af3a7010a1d) & [paper](https://arxiv.org/abs/1907.05982)


This year, we have 2 papers at ISMIR:
* *DrumGAN: Synthesis of Drum Sounds With Timbral Feature Conditioning Using Generative Adversarial Networks*, from **J. Nistal**, **S. Lattner**, and G. Richard
    * [Paper, poster & talk](https://program.ismir2020.net/poster_4-16.html)

* *Connective Fusion: Learning Transformational Joining of Sequences with Application to Melody Creation*, from **T. Akama**
    * [Paper, poster & talk](https://program.ismir2020.net/poster_1-05.html)

<br>


## 2. CSL and Artists - Interview with producer Donn Healy

 ![cslbanner]({{ site.baseurl }}/assets/img/virtual-booth-sonycsl/credo3.png)


Artistic collaborations are an important part of CSLâ€™s work. For us, creativity is a key value. We are working with musicians and music producers. We integrate our technology in their creative processes. For the last few years, people have been worried that A.I. would replace musicians. At CSL we want music production to remain human-centered. Therefore, interaction is an everyday keyword, whether its is between an artist and a machine or between musicians and scientists.

Music is one obsession of humans, and so is technological progress. Both have always gone hand in hand. To paraphrase Robert Moog, at CSL, our ambition is simply to *"build stuff that musicians want to use"*. We have detailled this approach during this year's ICASSP Sony workshop: ***[The sound of AI](https://drive.google.com/file/d/1ECoZtBlAW3mMt2JzToku1m21NoF6Slw1/view?usp=sharing)***.

 <!-- ![cslbanner](./Donn_intro.png) -->


For ISMIR 2020, we want to provide an insight on the journey of an artist discovering AI. Donn Healy has been working with us, he has devoted himself to the exploration of AI use in music, producing 12 tracks using our technology.
The video is gonna be posted on Monday.


<br>

## 3. Publicly Available Ressources

As said above, we provide artists with prototypes that encapsulate our technologies. We have three categories of prototypes:

* Compositional tools that operate on symbolic music or directly on audio.
* AI-based synthesizers and sound design tools.
* Mixing and mastering tools, that operate on the signal.

Even though the user interfaces and the plugins cannot be shared publicly, we usually publish papers about the underlying models. 


* Markov-Chain based models:
  * [Flow Machines](https://vimeo.com/442553142) : A music composition assistant.

* Gated Autoencoder based models
  * [DrumNet](https://sites.google.com/view/drum-generation) : A drum track generator using learned patterns of rhythmic interaction.
  * [BassNet](https://sonycslparis.github.io/bassnet/) : A generator of bass guitar tracks with learned interactive control.

* Variational Autoencoder based models
  * [PlanetDrums](https://sonycslparis.github.io/NeuralDrumMachine/) : A weird drum sounds generator.

* GAN-Based Models
  * [DrumGAN](https://sites.google.com/view/drumgan) : A drum sounds synthesizer with high-level control.

* Digital Signal Processing & Neural Networks
  * [ResonanceEQ](https://arxiv.org/abs/1807.08636) : A plugin that targets resonances, to enhance or to smoothen them.

<br>

## 4. Follow us !

(Icons are clickable)

<br>

<a href="https://www.twitter.com/sonycslmusic/" class="fa fa-twitter"></a> @SonyCSLMusic
<a href="https://www.instagram.com/sonycslmusic/" class="fa fa-instagram"></a> @SonyCSLMusic
<a href="https://www.facebook.com/SonyCSLMusicTeam" class="fa fa-facebook"></a> @SonyCSLMusicTeam 
<a href="https://www.linkedin.com/company/sony-csl-music-team/" class="fa fa-linkedin"></a> Sony CSL Music Team

<!-- 
|<a href="https://www.twitter.com/sonycslmusic/" class="fa fa-twitter"></a>|<a href="https://www.instagram.com/sonycslmusic/" class="fa fa-instagram"></a>|<a href="https://www.facebook.com/SonyCSLMusicTeam" class="fa fa-facebook"></a> |<a href="https://www.linkedin.com/company/sony-csl-music-team/" class="fa fa-linkedin"></a> |
|:---:|:---:|:---:|:---:|
|@SonyCSLMusic|@SonyCSLMusic|@SonyCSLMusicTeam|Sony CSL Music Team| -->

